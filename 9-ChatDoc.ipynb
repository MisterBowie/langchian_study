{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in ./myenv/lib/python3.10/site-packages (0.8)\n",
      "Requirement already satisfied: pypdf in ./myenv/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./myenv/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: nltk in ./myenv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./myenv/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./myenv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./myenv/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: unstructured in ./myenv/lib/python3.10/site-packages (0.16.10)\n",
      "Requirement already satisfied: html5lib in ./myenv/lib/python3.10/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: emoji in ./myenv/lib/python3.10/site-packages (from unstructured) (2.14.0)\n",
      "Requirement already satisfied: chardet in ./myenv/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: unstructured-client in ./myenv/lib/python3.10/site-packages (from unstructured) (0.28.1)\n",
      "Requirement already satisfied: nltk in ./myenv/lib/python3.10/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: numpy<2 in ./myenv/lib/python3.10/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./myenv/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: wrapt in ./myenv/lib/python3.10/site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: python-oxmsg in ./myenv/lib/python3.10/site-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: python-iso639 in ./myenv/lib/python3.10/site-packages (from unstructured) (2024.10.22)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.10/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: python-magic in ./myenv/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: backoff in ./myenv/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: psutil in ./myenv/lib/python3.10/site-packages (from unstructured) (6.1.1)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.10/site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: lxml in ./myenv/lib/python3.10/site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: langdetect in ./myenv/lib/python3.10/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: dataclasses-json in ./myenv/lib/python3.10/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: rapidfuzz in ./myenv/lib/python3.10/site-packages (from unstructured) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions in ./myenv/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: filetype in ./myenv/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./myenv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./myenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.23.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./myenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: webencodings in ./myenv/lib/python3.10/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in ./myenv/lib/python3.10/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: click in ./myenv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./myenv/lib/python3.10/site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Requirement already satisfied: joblib in ./myenv/lib/python3.10/site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: olefile in ./myenv/lib/python3.10/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests->unstructured) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests->unstructured) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.10/site-packages (from requests->unstructured) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:997)'))': /simple/pydantic/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:997)'))': /simple/pydantic/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:997)'))': /simple/pydantic/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pydantic<2.10.0,>=2.9.2\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (5.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (44.0.0)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.2.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.27.2)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in ./myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./myenv/lib/python3.10/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in ./myenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.8.0)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./myenv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.10/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (0.7.0)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Using cached pydantic_core-2.23.4-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./myenv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in ./myenv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./myenv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
      "Installing collected packages: pydantic-core, pydantic\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.4\n",
      "    Uninstalling pydantic-2.10.4:\n",
      "      Successfully uninstalled pydantic-2.10.4\n",
      "Successfully installed pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install docx2txt\n",
    "! pip install pypdf\n",
    "! pip install  nltk\n",
    "! pip install unstructured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-c974b5d99e5f42048860411998b7efa3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from openai.env file\n",
    "load_dotenv(\"openai.env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_key = os.getenv(\"DS_KEY\")\n",
    "api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "print(api_key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = api_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个测试，加载docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn\\n\\n\\n\\n二、财务状况概述\\n\\n截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下：\\n\\n1. 资产总额：人民币1.2亿元，较上年同期下降30%。\\n\\n2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。\\n\\n3. 营业收入：人民币3000万元，较上年同期下降60%。\\n\\n4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。\\n\\n6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。\\n\\n7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。\\n\\n\\n\\n三、主营业务及市场状况\\n\\n宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有：\\n\\n1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。\\n\\n3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n\\n\\n四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：\\n\\n1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。\\n\\n2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。\\n\\n4. 其他应付款项：包括税费、租赁费用等其他应付款项累计约人民币100万元。\\n\\n\\n\\n五、资产清单\\n\\n宏图科技发展有限公司目前拥有的主要资产包括：\\n\\n1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。\\n\\n2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。\\n\\n3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。\\n\\n4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。\\n\\n\\n\\n六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。\\n\\n2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。\\n\\n4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n\\n\\n七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。\\n\\n\\n\\n报告撰写日期：2023年4月20日'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import Docx2txtLoader\n",
    "#定义chatdoc\n",
    "\n",
    "class ChatDoc():\n",
    "    def getFile():\n",
    "        loader = Docx2txtLoader('example/fake.docx')\n",
    "        text = loader.load()\n",
    "        return text\n",
    "    \n",
    "ChatDoc.getFile()[0].page_content\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载pdf文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'example/fake.pdf', 'page': 0}, page_content=' 一、公司基本信息 名称：宏图科技发展有限公司 注册地址：江苏省南京市雨花台区软件大道101号 成立日期：2011年5月16日 法定代表人：李强 注册资本：人民币5000万元 员工人数：约200人 联系电话：025-88888888 电子邮箱：info@hongtutech.cn  二、财务状况概述 截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下： 1. 资产总额：人民币1.2亿元，较上年同期下降30%。 2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。 3. 营业收入：人民币3000万元，较上年同期下降60%。 4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。 5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。 6. 存货： 存货积压严重， 库存商品价值约为人民币400万元， 大部分产品滞销。 7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。  三、主营业务及市场状况 宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有： 1. 产品同质化严重，缺乏核心竞争力。 2. 新产品开发进度缓慢，未能及时抓住市场需求变化。 3. 市场营销策略不当，导致市场份额大幅缩水。 '),\n",
       " Document(metadata={'source': 'example/fake.pdf', 'page': 1}, page_content='4. 行业内新兴企业崛起迅速，原有客户流失严重。  四、债权债务情况 宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下： 1. 银行贷款： 公司向多家银行贷款总额达人民币1亿元， 部分贷款已逾期未还。 2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。 3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。 4. 其他应付款项： 包括税费、 租赁费用等其他应付款项累计约人民币100万元。  五、资产清单 宏图科技发展有限公司目前拥有的主要资产包括： 1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。 2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。 3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。 4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。  六、潜在风险及预警 1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。 2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。 3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。 4. 法律风险： 因未能按时支付债务和相关费用， 可能面临相关法律诉讼或处罚。  七、结论与建议 综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏'),\n",
       " Document(metadata={'source': 'example/fake.pdf', 'page': 2}, page_content='图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。 同时， 在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。  报告撰写日期：2023年4月20日 ')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "class ChatDoc():\n",
    "    def getFile():\n",
    "        try:\n",
    "            loader = PyPDFLoader(\"example/fake.pdf\")\n",
    "            return loader.load()\n",
    "        except Exception as e:\n",
    "            print(f'Error: loading files: {e}')\n",
    "\n",
    "\n",
    "ChatDoc.getFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载Excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: loading files: No module named 'unstructured'\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "\n",
    "class ChatDoc():\n",
    "    def getFile():\n",
    "        try:\n",
    "            loader = UnstructuredExcelLoader(\"example/fake.xlsx\",mode='elements')\n",
    "            return loader.load()\n",
    "        except Exception as e:\n",
    "            print(f'Error: loading files: {e}')\n",
    "\n",
    "\n",
    "ChatDoc.getFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'example/fake.docx'}, page_content='一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn\\n\\n二、财务状况概述\\n\\n截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 资产总额：人民币1.2亿元，较上年同期下降30%。\\n\\n2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。\\n\\n3. 营业收入：人民币3000万元，较上年同期下降60%。\\n\\n4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。'), Document(metadata={'source': 'example/fake.docx'}, page_content='6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。\\n\\n7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。\\n\\n三、主营业务及市场状况\\n\\n宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有：\\n\\n1. 产品同质化严重，缺乏核心竞争力。'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。\\n\\n3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：\\n\\n1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。\\n\\n4. 其他应付款项：包括税费、租赁费用等其他应付款项累计约人民币100万元。\\n\\n五、资产清单\\n\\n宏图科技发展有限公司目前拥有的主要资产包括：\\n\\n1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。\\n\\n3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。\\n\\n4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。\\n\\n六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。\\n\\n4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n七、结论与建议'), Document(metadata={'source': 'example/fake.docx'}, page_content='七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。\\n\\n报告撰写日期：2023年4月20日')]\n"
     ]
    }
   ],
   "source": [
    "# 整合三种加载方式的代码,增加文本切割\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredExcelLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.text = None\n",
    "        self.splitText = []\n",
    "        self.doc = None\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        laoders = {\n",
    "            \"docx\": Docx2txtLoader,\n",
    "            \"pdf\": PyPDFLoader,\n",
    "            \"xlsx\": UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = laoders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                return loader.load()\n",
    "            except Exception as e:\n",
    "                print(f'Error: loading files: {e}')\n",
    "        else:\n",
    "            e = \"Unsupported file type\"\n",
    "            print(f'Error: loading files: {e}')\n",
    "\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile()\n",
    "        if full_text != None:\n",
    "            splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "            self.splitText = splitter.split_documents(full_text)\n",
    "\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = 'example/fake.docx'\n",
    "chat_doc.splitSentences()\n",
    "print(chat_doc.splitText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量化储存索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitText [Document(metadata={'source': 'example/fake.docx'}, page_content='一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn\\n\\n二、财务状况概述'), Document(metadata={'source': 'example/fake.docx'}, page_content='二、财务状况概述\\n\\n截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下：\\n\\n1. 资产总额：人民币1.2亿元，较上年同期下降30%。\\n\\n2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。\\n\\n3. 营业收入：人民币3000万元，较上年同期下降60%。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。\\n\\n6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。\\n\\n7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。'), Document(metadata={'source': 'example/fake.docx'}, page_content='三、主营业务及市场状况\\n\\n宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有：\\n\\n1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。'), Document(metadata={'source': 'example/fake.docx'}, page_content='3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：\\n\\n1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。\\n\\n4. 其他应付款项：包括税费、租赁费用等其他应付款项累计约人民币100万元。\\n\\n五、资产清单\\n\\n宏图科技发展有限公司目前拥有的主要资产包括：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。\\n\\n2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。\\n\\n3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。\\n\\n4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。\\n\\n2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n七、结论与建议'), Document(metadata={'source': 'example/fake.docx'}, page_content='七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。'), Document(metadata={'source': 'example/fake.docx'}, page_content='报告撰写日期：2023年4月20日')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama3.1\\\" not found, try pulling it first\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m chat_doc\u001b[38;5;241m.\u001b[39msplitSentences()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplitText\u001b[39m\u001b[38;5;124m\"\u001b[39m,chat_doc\u001b[38;5;241m.\u001b[39msplitText)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mchat_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maskAndFindFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m公司名字是什么?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 50\u001b[0m, in \u001b[0;36mChatDoc.askAndFindFiles\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maskAndFindFiles\u001b[39m(\u001b[38;5;28mself\u001b[39m,query):\n\u001b[0;32m---> 50\u001b[0m     db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddingAndVectorDB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     retriever \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retriever\u001b[38;5;241m.\u001b[39minvoke(query)\n",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m, in \u001b[0;36mChatDoc.embeddingAndVectorDB\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membeddingAndVectorDB\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     42\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     db \u001b[38;5;241m=\u001b[39m\u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitText\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:214\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m--> 214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:202\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:176\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference API HTTP code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;241m%\u001b[39m (res\u001b[38;5;241m.\u001b[39mstatus_code, res\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     t \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama3.1\\\" not found, try pulling it first\"}"
     ]
    }
   ],
   "source": [
    "# 整合三种加载方式的代码,增加文本切割\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredExcelLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.text = None\n",
    "        self.splitText = []\n",
    "        self.doc = None\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        laoders = {\n",
    "            \"docx\": Docx2txtLoader,\n",
    "            \"pdf\": PyPDFLoader,\n",
    "            \"xlsx\": UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = laoders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                return loader.load()\n",
    "            except Exception as e:\n",
    "                print(f'Error: loading files: {e}')\n",
    "        else:\n",
    "            e = \"Unsupported file type\"\n",
    "            print(f'Error: loading files: {e}')\n",
    "    # 文本切割\n",
    "\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile()\n",
    "        if full_text != None:\n",
    "            splitter = CharacterTextSplitter(chunk_size=160, chunk_overlap=20)\n",
    "            self.splitText = splitter.split_documents(full_text)\n",
    "\n",
    "    # 向量化以及向量储存\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = OllamaEmbeddings(model=\"llama3.1\")\n",
    "        db =Chroma.from_documents(\n",
    "            documents = self.splitText,\n",
    "            embedding = embeddings,\n",
    "        )\n",
    "        return db\n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,query):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        retriever = db.as_retriever()\n",
    "        return retriever.invoke(query)\n",
    "\n",
    "\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = 'example/fake.docx'\n",
    "chat_doc.splitSentences()\n",
    "print(\"splitText\",chat_doc.splitText)\n",
    "chat_doc.askAndFindFiles(\"公司名字是什么?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用多重查询提高精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 141, which is longer than the specified 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitText [Document(metadata={'source': 'example/fake.docx'}, page_content='一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人'), Document(metadata={'source': 'example/fake.docx'}, page_content='员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn\\n\\n二、财务状况概述\\n\\n截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 资产总额：人民币1.2亿元，较上年同期下降30%。\\n\\n2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。\\n\\n3. 营业收入：人民币3000万元，较上年同期下降60%。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。'), Document(metadata={'source': 'example/fake.docx'}, page_content='6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。\\n\\n7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。\\n\\n三、主营业务及市场状况'), Document(metadata={'source': 'example/fake.docx'}, page_content='三、主营业务及市场状况\\n\\n宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。\\n\\n3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n四、债权债务情况'), Document(metadata={'source': 'example/fake.docx'}, page_content='四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：\\n\\n1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。\\n\\n2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。\\n\\n4. 其他应付款项：包括税费、租赁费用等其他应付款项累计约人民币100万元。\\n\\n五、资产清单\\n\\n宏图科技发展有限公司目前拥有的主要资产包括：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。\\n\\n2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。\\n\\n3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。\\n\\n六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n七、结论与建议'), Document(metadata={'source': 'example/fake.docx'}, page_content='综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。'), Document(metadata={'source': 'example/fake.docx'}, page_content='报告撰写日期：2023年4月20日')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /embeddings in 0.473322 seconds\n",
      "INFO:openai._base_client:Retrying request to /embeddings in 0.988611 seconds\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpcore/_sync/http_proxy.py:297\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(msg)\n\u001b[1;32m    299\u001b[0m stream \u001b[38;5;241m=\u001b[39m connect_response\u001b[38;5;241m.\u001b[39mextensions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_stream\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mProxyError\u001b[0m: 400 Bad Request",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mProxyError\u001b[0m: 400 Bad Request",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain.retrievers.multi_query\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplitText\u001b[39m\u001b[38;5;124m\"\u001b[39m, chat_doc\u001b[38;5;241m.\u001b[39msplitText)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mchat_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maskAndFindFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m公司叫什么名字?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m, in \u001b[0;36mChatDoc.askAndFindFiles\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maskAndFindFiles\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[0;32m---> 55\u001b[0m     db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddingAndVectorDB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m     retriever_from_llm \u001b[38;5;241m=\u001b[39m MultiQueryRetriever\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[1;32m     58\u001b[0m         retriever\u001b[38;5;241m=\u001b[39mdb\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[1;32m     59\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     60\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m, in \u001b[0;36mChatDoc.embeddingAndVectorDB\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membeddingAndVectorDB\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     46\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitText\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1017\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1014\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1017\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1014\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/person/code/langchain/myenv/lib/python3.12/site-packages/openai/_base_client.py:1027\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1018\u001b[0m             input_options,\n\u001b[1;32m   1019\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1024\u001b[0m         )\n\u001b[1;32m   1026\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1031\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1036\u001b[0m )\n\u001b[1;32m   1037\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "# 索引并使用自然语言来查询索引\n",
    "\n",
    "import logging\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredExcelLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.text = None\n",
    "        self.splitText = []\n",
    "        self.doc = None\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        laoders = {\n",
    "            \"docx\": Docx2txtLoader,\n",
    "            \"pdf\": PyPDFLoader,\n",
    "            \"xlsx\": UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = laoders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                return loader.load()\n",
    "            except Exception as e:\n",
    "                print(f'Error: loading files: {e}')\n",
    "        else:\n",
    "            e = \"Unsupported file type\"\n",
    "            print(f'Error: loading files: {e}')\n",
    "    # 文本切割\n",
    "\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile()\n",
    "        if full_text != None:\n",
    "            splitter = CharacterTextSplitter(chunk_size=120, chunk_overlap=20)\n",
    "            self.splitText = splitter.split_documents(full_text)\n",
    "\n",
    "    # 向量化以及向量储存\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        db = Chroma.from_documents(\n",
    "            documents=self.splitText,\n",
    "            embedding=embeddings,\n",
    "        )\n",
    "        return db\n",
    "    # 提问并找到相关的文本块\n",
    "\n",
    "    def askAndFindFiles(self, query):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        llm = ChatOpenAI(temperature=0)\n",
    "        retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "            retriever=db.as_retriever(),\n",
    "            llm=llm,\n",
    "        )\n",
    "        return retriever_from_llm.get_relevant_documents(query)\n",
    "\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = 'example/fake.docx'\n",
    "chat_doc.splitSentences()\n",
    "# 设置下logging查看生成查询\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "print(\"splitText\", chat_doc.splitText)\n",
    "chat_doc.askAndFindFiles(\"公司叫什么名字?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "/var/folders/sy/dfvmk27d1hdbrm5h8p4qwm3m0000gn/T/ipykernel_9573/4251526084.py:68: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return retriever_from_llm.get_relevant_documents(question)\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question:', '公司名称是什么?', '1. 公司的全称或简称是什么?', '2. 公司在哪些地方被提及或出现过?', '3. 公司的描述或定义包括哪些关键词?', 'These alternative questions can help to retrieve relevant documents from a vector database by:', '* Focusing on specific aspects of the company name (version 1)', '* Considering broader contexts where the company might be mentioned (version 2)', \"* Emphasizing key concepts related to the company's description (version 3)\", 'By generating multiple perspectives, we can increase the chances of retrieving relevant documents that may not have been found using a single query.']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'example/fake.docx'}, page_content='报告撰写日期：2023年4月20日'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n七、结论与建议'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。\\n\\n2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。\\n\\n6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。\\n\\n3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：'), Document(metadata={'source': 'example/fake.docx'}, page_content='六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。\\n\\n2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。'), Document(metadata={'source': 'example/fake.docx'}, page_content='七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。')]\n"
     ]
    }
   ],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings,ChatOllama\n",
    "from langchain.vectorstores import  Chroma\n",
    "#引入openai和多重向量检索\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        loaders = {\n",
    "            \"docx\":Docx2txtLoader,\n",
    "            \"pdf\":PyPDFLoader,\n",
    "            \"xlsx\":UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = loaders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                text = loader.load()\n",
    "                return text\n",
    "            except Exception as e: \n",
    "                print(f\"Error loading {file_extension} files:{e}\") \n",
    "        else:\n",
    "             print(f\"Unsupported file extension: {file_extension}\")\n",
    "             return  None \n",
    "\n",
    "    #处理文档的函数\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile() #获取文档内容\n",
    "        if full_text != None:\n",
    "            #对文档进行分割\n",
    "            text_split = CharacterTextSplitter(\n",
    "                chunk_size=150,\n",
    "                chunk_overlap=20,\n",
    "            )\n",
    "            texts = text_split.split_documents(full_text)\n",
    "            self.splitText = texts\n",
    "    \n",
    "    #向量化与向量存储\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"llama3.1\"\n",
    "        )\n",
    "        db =Chroma.from_documents(\n",
    "            documents = self.splitText,\n",
    "            embedding = embeddings,\n",
    "        )\n",
    "        return db\n",
    "    \n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        #把问题交给LLM进行多角度的扩展\n",
    "        llm = ChatOllama(temperature=0,model=\"llama3.1\")\n",
    "        retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "            retriever = db.as_retriever(),\n",
    "            llm = llm,\n",
    "        )\n",
    "        return retriever_from_llm.get_relevant_documents(question)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "#设置下logging查看生成查询\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "unique_doc = chat_doc.askAndFindFiles(\"公司名称是什么?\")\n",
    "print(unique_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通义千问处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitText [Document(metadata={'source': 'example/fake.docx'}, page_content='一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn'), Document(metadata={'source': 'example/fake.docx'}, page_content='二、财务状况概述\\n\\n截至2023年第一季度，宏图科技发展有限公司财务状况堪忧，具体情况如下：\\n\\n1. 资产总额：人民币1.2亿元，较上年同期下降30%。\\n\\n2. 负债总额：人民币1.8亿元，较上年同期上升50%，资不抵债。\\n\\n3. 营业收入：人民币3000万元，较上年同期下降60%。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。\\n\\n6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。'), Document(metadata={'source': 'example/fake.docx'}, page_content='7. 应收账款：应收账款高达人民币600万元，回收难度大，坏账准备不足。\\n\\n三、主营业务及市场状况\\n\\n宏图科技发展有限公司主要从事计算机软件的研发与销售。近年来，由于市场竞争加剧、技术更新换代速度快和管理层决策失误等原因，公司主营业务收入持续下降。目前，公司面临的主要问题有：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 产品同质化严重，缺乏核心竞争力。\\n\\n2. 新产品开发进度缓慢，未能及时抓住市场需求变化。\\n\\n3. 市场营销策略不当，导致市场份额大幅缩水。\\n\\n4. 行业内新兴企业崛起迅速，原有客户流失严重。\\n\\n四、债权债务情况\\n\\n宏图科技发展有限公司目前面临的债务问题严峻，具体情况如下：'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。\\n\\n2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 其他应付款项：包括税费、租赁费用等其他应付款项累计约人民币100万元。\\n\\n五、资产清单\\n\\n宏图科技发展有限公司目前拥有的主要资产包括：\\n\\n1. 固定资产：公司办公用房和设备原值合计人民币800万元，累计折旧约400万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='2. 无形资产：包括软件著作权、专利权等无形资产原值合计人民币300万元。\\n\\n3. 存货资产：存货包括已完成软件产品和半成品，价值约为人民币400万元。\\n\\n4. 应收账款：主要包括对外销售软件的应收账款合计人民币600万元。\\n\\n六、潜在风险及预警'), Document(metadata={'source': 'example/fake.docx'}, page_content='六、潜在风险及预警\\n\\n1. 经营风险：由于连续亏损，公司可能面临破产清算的风险。\\n\\n2. 债务风险：负债累累，若短期内无法筹措足够资金偿还债务，可能面临诉讼或资产被查封的风险。\\n\\n3. 市场风险：行业竞争加剧和市场需求不明朗，可能导致公司未来业绩继续恶化。'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 法律风险：因未能按时支付债务和相关费用，可能面临相关法律诉讼或处罚。\\n\\n七、结论与建议'), Document(metadata={'source': 'example/fake.docx'}, page_content='七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。'), Document(metadata={'source': 'example/fake.docx'}, page_content='报告撰写日期：2023年4月20日')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. 这家公司的名字叫什么？', '2. 公司的全称是什么？', '3. 我想了解这家公司的名称，可以告诉我吗？']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'example/fake.docx'}, page_content='报告撰写日期：2023年4月20日'), Document(metadata={'source': 'example/fake.docx'}, page_content='4. 净利润：亏损人民币800万元，去年同期为盈利人民币200万元。\\n\\n5. 现金流量：公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营。\\n\\n6. 存货：存货积压严重，库存商品价值约为人民币400万元，大部分产品滞销。'), Document(metadata={'source': 'example/fake.docx'}, page_content='一、公司基本信息\\n\\n名称：宏图科技发展有限公司\\n\\n注册地址：江苏省南京市雨花台区软件大道101号\\n\\n成立日期：2011年5月16日\\n\\n法定代表人：李强\\n\\n注册资本：人民币5000万元\\n\\n员工人数：约200人\\n\\n联系电话：025-88888888\\n\\n电子邮箱：info@hongtutech.cn'), Document(metadata={'source': 'example/fake.docx'}, page_content='1. 银行贷款：公司向多家银行贷款总额达人民币1亿元，部分贷款已逾期未还。\\n\\n2. 供应商欠款：因现金流紧张，公司拖欠供应商货款达人民币300万元。\\n\\n3. 员工工资及社保：由于资金链断裂，公司拖欠员工工资及社保费用共计人民币200万元。'), Document(metadata={'source': 'example/fake.docx'}, page_content='七、结论与建议\\n\\n综上所述，宏图科技发展有限公司目前处于财务困境之中，若无外部资金注入或业务转型成功，短期内难以扭转局势。对于不良资产收购方来说，在考虑收购宏图科技的相关资产前，建议进行深入的尽职调查，并制定详细的风险控制和资产处置方案。同时，在估值时应充分考虑到公司所面临的各种潜在风险和清收难度。')]\n"
     ]
    }
   ],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain.vectorstores import  Chroma\n",
    "from langchain_ollama import ChatOllama,OllamaEmbeddings\n",
    "#引入openai和多重向量检索\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        loaders = {\n",
    "            \"docx\":Docx2txtLoader,\n",
    "            \"pdf\":PyPDFLoader,\n",
    "            \"xlsx\":UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = loaders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                text = loader.load()\n",
    "                return text\n",
    "            except Exception as e: \n",
    "                print(f\"Error loading {file_extension} files:{e}\") \n",
    "        else:\n",
    "             print(f\"Unsupported file extension: {file_extension}\")\n",
    "             return  None \n",
    "\n",
    "    #处理文档的函数\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile() #获取文档内容\n",
    "        if full_text != None:\n",
    "            #对文档进行分割\n",
    "            text_split = CharacterTextSplitter(\n",
    "                chunk_size=150,\n",
    "                chunk_overlap=20,\n",
    "            )\n",
    "            texts = text_split.split_documents(full_text)\n",
    "            self.splitText = texts\n",
    "            print(\"splitText\",self.splitText)\n",
    "    #向量化与向量存储\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"qwen2.5:7b\"\n",
    "        )\n",
    "        db =Chroma.from_documents(\n",
    "            documents = self.splitText,\n",
    "            embedding = embeddings,\n",
    "        )\n",
    "        return db\n",
    "    \n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        #把问题交给LLM进行多角度的扩展\n",
    "        llm = ChatOllama(temperature=0,model=\"qwen2.5:7b\")\n",
    "        retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "            retriever = db.as_retriever(),\n",
    "            llm = llm,\n",
    "        )\n",
    "        return retriever_from_llm.get_relevant_documents(question)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "#设置下logging查看生成查询\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "unique_doc = chat_doc.askAndFindFiles(\"公司名称是什么?\")\n",
    "print(unique_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
